
**Big Data Architechture**

Batch and stream processing data
![image](https://user-images.githubusercontent.com/38088886/111028787-cb3b8f80-83f0-11eb-8a4a-caedcd6b5ce9.png)


![image](https://user-images.githubusercontent.com/38088886/111028846-47ce6e00-83f1-11eb-9ca7-eb092f4642fc.png)

Databricks

![image](https://user-images.githubusercontent.com/38088886/111028973-17d39a80-83f2-11eb-9d91-8557caa3b3a0.png)

Choosing pipeline orchestration service

![image](https://user-images.githubusercontent.com/38088886/111029062-89134d80-83f2-11eb-9af7-e40803fe0aeb.png)


Data ingestion tool

Azcopy 
* works in both windows and linux environment
* supports concurrent processing
* resume from where it left when failed

Adlcopy
* used to copy data ONLY to Datalake. not from Datalake

Distcp
* Ingest data from HDFS into Azure data lake

Sqoop
* transfer data from RDBMS into HDFS
![image](https://user-images.githubusercontent.com/38088886/111029252-a5fc5080-83f3-11eb-9eac-60e6999a8973.png)
